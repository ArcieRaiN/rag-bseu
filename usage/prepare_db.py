"""
PIPELINE 1: –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
- LlamaIndex –¥–ª—è —á–∞–Ω–∫–∏–Ω–≥–∞ PDF
- Ollama –¥–ª—è –±–∞—Ç—á–µ–≤–æ–≥–æ enrichment —á–∞–Ω–∫–æ–≤
- FAISS –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
"""

from pathlib import Path

from src.prepare_db.knowledge_builder import KnowledgeBaseBuilder, BuildConfig
from src.main.ollama_client import OllamaClient, OllamaConfig


def main() -> None:
    """Entrypoint –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω."""
    # –ö–æ—Ä–µ–Ω—å src/
    src_dir = Path(__file__).resolve().parent.parent  # rag-bseu/src

    # –ü–∞–ø–∫–∞ —Å PDF-–¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
    docs_dir = src_dir / "usage" / "documents"

    pdf_files = list(docs_dir.glob("*.pdf"))
    if not pdf_files:
        print(f"‚ùå –ù–µ—Ç PDF-—Ñ–∞–π–ª–æ–≤ –≤ {docs_dir}")
        return

    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ PDF-—Ñ–∞–π–ª–æ–≤: {len(pdf_files)}")

    # –ü–∞–ø–∫–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞
    vector_store_dir = src_dir / "usage" / "vector_store"
    vector_store_dir.mkdir(parents=True, exist_ok=True)

    print("üîß –°—Ç—Ä–æ–∏–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π —á–µ—Ä–µ–∑ LlamaIndex + Ollama enrichment...")
    print("   (–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è –∏–∑-–∑–∞ LLM-–∑–∞–ø—Ä–æ—Å–æ–≤)")

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = BuildConfig(
        documents_dir=docs_dir,
        output_dir=vector_store_dir,
        vector_dim=256,
    )

    # –°–æ–∑–¥–∞—ë–º Ollama –∫–ª–∏–µ–Ω—Ç —Å –º–æ–¥–µ–ª—å—é llama3-chatqa:latest
    ollama_config = OllamaConfig(model="llama3-chatqa:latest")
    llm_client = OllamaClient(config=ollama_config)

    # –°—Ç—Ä–æ–∏–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
    builder = KnowledgeBaseBuilder(config=config, llm_client=llm_client)
    builder.build()

    print("‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞!")
    print(f"üìÅ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {vector_store_dir}")

if __name__ == "__main__":
    main()
