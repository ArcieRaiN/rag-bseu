from pathlib import Path
import json

from src.prepare_db.chunk_maker import ChunkMaker
from src.main.vectorizer import HashVectorizer


def main():
    # –ö–æ—Ä–µ–Ω—å src/
    src_dir = Path(__file__).resolve().parent.parent  # rag-bseu/src

    # PDF-–¥–æ–∫—É–º–µ–Ω—Ç—ã
    docs_dir = src_dir / "prepare_db" / "documents"

    pdf_files = list(docs_dir.glob("*.pdf"))
    if not pdf_files:
        print(f"‚ùå –ù–µ—Ç PDF-—Ñ–∞–π–ª–æ–≤ –≤ {docs_dir}")
        return

    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ PDF-—Ñ–∞–π–ª–æ–≤: {len(pdf_files)}")

    # ‚ö†Ô∏è –£–í–ï–õ–ò–ß–ï–ù–ù–ê–Ø –†–ê–ó–ú–ï–†–ù–û–°–¢–¨
    vectorizer = HashVectorizer(dimension=256)

    # vector_store
    vector_store_dir = src_dir / "prepare_db" / "vector_store"
    vector_store_dir.mkdir(parents=True, exist_ok=True)

    print("üîß –°—Ç—Ä–æ–∏–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∏–Ω–¥–µ–∫—Å –∏–∑ PDF...")
    chunk_maker = ChunkMaker(
        vectorizer=vectorizer,
        documents_dir=docs_dir,
        min_words=20,
    )

    artifacts = chunk_maker.build_from_pdfs(output_dir=vector_store_dir)

    print("‚úÖ –ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω!")
    print(f"üìÅ vector_store: {vector_store_dir}")

    with open(artifacts.data_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    print(f"üìä –í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —á–∞–Ω–∫–æ–≤: {len(data)}")


if __name__ == "__main__":
    main()
