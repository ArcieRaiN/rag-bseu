from __future__ import annotations

"""
–ù–µ–±–æ–ª—å—à–æ–π HTTP‚Äë–∫–ª–∏–µ–Ω—Ç –¥–ª—è Ollama.

–ó–∞–¥–∞—á–∏:
- –∏–Ω–∫–∞–ø—Å—É–ª–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å HTTP API
- –¥–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π, –ø–æ–¥–º–µ–Ω—è–µ–º—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —é–Ω–∏—Ç‚Äë—Ç–µ—Å—Ç–æ–≤
- –Ω–µ –∑–∞–Ω–∏–º–∞—Ç—å—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ RAG (—Ç–æ–ª—å–∫–æ —Å–ª—É–∂–µ–±–Ω—ã–µ –≤—ã–∑–æ–≤—ã)
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional

import requests


@dataclass
class OllamaConfig:
    base_url: str = "http://localhost:11434"
    model: str = "qwen2.5:7b"
    timeout: float = 120.0
    temperature: float = 0.0
    top_p: float = 0.9
    repeat_penalty: float = 1.1
    num_predict: int = 800
    format: Optional[str] = None

class OllamaClient:
    """
    –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ Ollama HTTP API.

    –í–ê–ñ–ù–û:
    - —ç—Ç–æ—Ç –∫–ª–∏–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è:
      * enrichment —á–∞–Ω–∫–æ–≤ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –ë–î
      * enrichment –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
      * LLM‚Äëbased reranking
    - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–¥–µ—Å—å –ù–ï —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è.
    """

    def __init__(self, config: Optional[OllamaConfig] = None):
        self.config = config or OllamaConfig()

    def reset_context(self) -> None:
        """
        –°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ –æ—á–∏—Å—Ç–∫—É –∫–µ—à–∞.
        
        –í Ollama —ç—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä keep_alive: "0" –≤ –∑–∞–ø—Ä–æ—Å–µ,
        –∫–æ—Ç–æ—Ä—ã–π –æ—á–∏—â–∞–µ—Ç –∫–µ—à –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç–∏.
        """
        url = f"{self.config.base_url}/api/generate"
        # –î–µ–ª–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å keep_alive: "0" –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∫–µ—à–∞
        payload: Dict[str, Any] = {
            "model": self.config.model,
            "prompt": "",  # –ü—É—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç
            "stream": False,
            "keep_alive": "0",  # –û—á–∏—â–∞–µ—Ç –∫–µ—à –º–æ–¥–µ–ª–∏
            "num_predict": 1,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        }
        try:
            resp = requests.post(url, json=payload, timeout=5.0)
            resp.raise_for_status()
        except Exception:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–∏ —Å–±—Ä–æ—Å–µ - —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ
            pass

    class OllamaClient:
        """
        –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ Ollama HTTP API.
        """

        def __init__(self, config: Optional[OllamaConfig] = None):
            self.config = config or OllamaConfig()

        def reset_context(self) -> None:
            url = f"{self.config.base_url}/api/generate"
            payload: Dict[str, Any] = {
                "model": self.config.model,
                "prompt": "",
                "stream": False,
                "keep_alive": "0",
                "num_predict": 1,
            }
            try:
                resp = requests.post(url, json=payload, timeout=5.0)
                resp.raise_for_status()
            except Exception:
                pass

        def generate(
                self,
                prompt: str,
                *,
                system_prompt: str | None = None,
                max_retries: int = 3,
                **params: Any,
        ) -> str:
            """
            –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—É—é completion –æ—Ç Ollama.
            """
            url = f"{self.config.base_url}/api/generate"

            payload: Dict[str, Any] = {
                "model": self.config.model,
                "prompt": prompt,
                "stream": False,

                # üîí –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                "temperature": self.config.temperature,
                "top_p": self.config.top_p,
                "repeat_penalty": self.config.repeat_penalty,
                "num_predict": self.config.num_predict,
            }

            if self.config.format:
                payload["format"] = self.config.format

            if system_prompt:
                payload["system"] = system_prompt

            # params –∏–º–µ—é—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ –∫–æ–Ω—Ñ–∏–≥–æ–º
            payload.update(params)

            import time
            for attempt in range(max_retries):
                try:
                    resp = requests.post(url, json=payload, timeout=self.config.timeout)
                    resp.raise_for_status()
                    data = resp.json()
                    return data.get("response", "")
                except requests.exceptions.ReadTimeout:
                    if attempt < max_retries - 1:
                        wait_time = (2 ** attempt) * 5
                        print(
                            f"‚ö†Ô∏è  –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLM "
                            f"(–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}). "
                            f"–ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {wait_time} —Å–µ–∫..."
                        )
                        time.sleep(wait_time)
                    else:
                        print(
                            f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫. "
                            f"–¢–∞–π–º–∞—É—Ç: {self.config.timeout} —Å–µ–∫"
                        )
                        raise
                except requests.exceptions.RequestException as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Ollama: {e}")
                    raise


